#!/usr/bin/env python3
"""
Script SIMPLE pour tester l'√âpoque 30 sur vid√©os
Usage: python test_video_epoch30.py
"""

import os
import cv2
import torch
import numpy as np
import torchvision.transforms as transforms
import torchvision.models.detection as detection_models
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
import glob

# Configuration simple
EPOCH_30_MODEL = "output_stable_training/stable_model_epoch_30.pth"
VIDEOS_DIR = "videos"
OUTPUT_DIR = "videos_output"
CONFIDENCE = 0.5  # Seuil optimal d√©montr√©

# Classes du mod√®le (28 classes)
CLASSES_FR = [
    'Personne', 'Sac √† dos', 'Valise', 'Sac √† main', 'Cravate',
    'Parapluie', 'S√®che-cheveux', 'Brosse √† dents', 'T√©l√©phone',
    'Ordinateur portable', 'Clavier', 'Souris', 'T√©l√©commande', 'T√©l√©vision',
    'Horloge', 'Micro-ondes', 'Bouteille', 'Tasse', 'Bol',
    'Couteau', 'Cuill√®re', 'Fourchette', 'Verre', 'R√©frig√©rateur',
    'Ciseaux', 'Livre', 'Vase', 'Chaise'
]

def load_epoch30_model():
    """Charge le mod√®le epoch 30"""
    print("ü§ñ Chargement du mod√®le √âpoque 30...")
    
    if not os.path.exists(EPOCH_30_MODEL):
        print(f"‚ùå Mod√®le non trouv√©: {EPOCH_30_MODEL}")
        return None, None
    
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        model = detection_models.fasterrcnn_resnet50_fpn(weights=None)
        in_features = model.roi_heads.box_predictor.cls_score.in_features
        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 29)  # 28 + fond
        
        model.load_state_dict(torch.load(EPOCH_30_MODEL, map_location=device))
        model.to(device)
        model.eval()
        
        print(f"‚úÖ Mod√®le epoch 30 charg√© sur {device}")
        return model, device
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return None, None

def find_videos():
    """Trouve toutes les vid√©os dans le dossier videos"""
    if not os.path.exists(VIDEOS_DIR):
        print(f"‚ùå Cr√©ez le dossier '{VIDEOS_DIR}' et placez-y vos vid√©os")
        return []
    
    # Extensions vid√©o support√©es
    extensions = ['*.mp4', '*.avi', '*.mov', '*.mkv', '*.wmv']
    videos = []
    
    for ext in extensions:
        videos.extend(glob.glob(os.path.join(VIDEOS_DIR, ext)))
        videos.extend(glob.glob(os.path.join(VIDEOS_DIR, ext.upper())))
    
    if not videos:
        print(f"‚ùå Aucune vid√©o trouv√©e dans '{VIDEOS_DIR}'")
        print("Formats support√©s: .mp4, .avi, .mov, .mkv, .wmv")
        return []
    
    print(f"üìπ {len(videos)} vid√©o(s) trouv√©e(s):")
    for i, video in enumerate(videos, 1):
        print(f"  {i}. {os.path.basename(video)}")
    
    return videos

def select_video(videos):
    """S√©lectionne une vid√©o √† traiter"""
    if len(videos) == 1:
        print(f"üìπ Vid√©o s√©lectionn√©e: {os.path.basename(videos[0])}")
        return videos[0]
    
    while True:
        try:
            choice = input(f"\nChoisissez une vid√©o (1-{len(videos)}) ou 'q' pour quitter: ").strip()
            if choice.lower() == 'q':
                return None
            
            idx = int(choice) - 1
            if 0 <= idx < len(videos):
                return videos[idx]
            else:
                print(f"‚ùå Choisissez un nombre entre 1 et {len(videos)}")
        except ValueError:
            print("‚ùå Entrez un nombre valide")

def process_video(model, device, video_path):
    """Traite une vid√©o avec d√©tection"""
    print(f"\nüé¨ Traitement de: {os.path.basename(video_path)}")
    
    # Ouvrir la vid√©o
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"‚ùå Impossible d'ouvrir: {video_path}")
        return False
    
    # Propri√©t√©s vid√©o
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"üìä Vid√©o: {width}x{height} √† {fps} FPS, {total_frames} frames")
    print(f"‚è±Ô∏è Dur√©e: {total_frames/fps:.1f} secondes")
    
    # Fichier de sortie
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    output_path = os.path.join(OUTPUT_DIR, f"detected_{os.path.basename(video_path)}")
    
    # Writer pour sauvegarder
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    # Transformation pour le mod√®le
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    # Couleurs al√©atoires pour les classes
    np.random.seed(42)
    colors = [(np.random.randint(50, 255), np.random.randint(50, 255), np.random.randint(50, 255)) 
              for _ in range(28)]
    
    frame_count = 0
    total_detections = 0
    
    print("üöÄ Traitement en cours (vitesse maximale)...")
    print("üí° Traitement sans affichage pour performance optimale")
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            # Pr√©traitement pour le mod√®le
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frame_tensor = transform(frame_rgb).unsqueeze(0).to(device)
            
            # D√©tection
            with torch.no_grad():
                predictions = model(frame_tensor)
            
            # Extraire r√©sultats
            boxes = predictions[0]['boxes'].cpu().numpy()
            labels = predictions[0]['labels'].cpu().numpy()
            scores = predictions[0]['scores'].cpu().numpy()
            
            # Filtrer par confiance
            mask = scores > CONFIDENCE
            boxes = boxes[mask]
            labels = labels[mask]
            scores = scores[mask]
            
            frame_detections = len(boxes)
            total_detections += frame_detections
            
            # Dessiner les d√©tections
            for box, label, score in zip(boxes, labels, scores):
                x1, y1, x2, y2 = box.astype(int)
                class_idx = label - 1  # -1 car 0 est le fond
                
                if 0 <= class_idx < 28:
                    class_name = CLASSES_FR[class_idx]
                    color = colors[class_idx]
                    
                    # Rectangle de d√©tection
                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                    
                    # Texte avec nom et confiance
                    text = f"{class_name}: {score:.2f}"
                    (text_width, text_height), _ = cv2.getTextSize(
                        text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
                    )
                    
                    # Fond du texte
                    cv2.rectangle(frame, (x1, y1-text_height-10), 
                                (x1+text_width, y1), color, -1)
                    
                    # Texte
                    cv2.putText(frame, text, (x1, y1-5), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)
            
            # Informations sur la frame
            info_text = f"Frame: {frame_count}/{total_frames} | Objets: {frame_detections} | Total: {total_detections}"
            cv2.putText(frame, info_text, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # Informations du mod√®le
            model_info = f"Modele: Epoque 30 | Confiance: {CONFIDENCE} | F1: 49.86%"
            cv2.putText(frame, model_info, (10, height-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            # Sauvegarder la frame directement (pas d'affichage)
            writer.write(frame)
            
            # Affichage progression moins fr√©quent pour plus de vitesse
            if frame_count % 100 == 0:
                progress = (frame_count / total_frames) * 100
                print(f"üìà Progression: {progress:.1f}% - {total_detections} d√©tections totales")
    
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Arr√™t par Ctrl+C")
    
    finally:
        # Nettoyage
        cap.release()
        writer.release()
        
        # Statistiques finales
        print(f"\nüìä R√âSULTATS FINAUX:")
        print(f"   üé¨ Frames trait√©es: {frame_count}/{total_frames}")
        print(f"   üîç Total d√©tections: {total_detections}")
        print(f"   üìà Moyenne par frame: {total_detections/frame_count:.1f}")
        print(f"   üíæ Vid√©o sauvegard√©e: {output_path}")
        
        return True

def main():
    """Fonction principale"""
    print("="*60)
    print("üé¨ TEST VID√âO SIMPLE - MOD√àLE √âPOQUE 30")
    print("="*60)
    print("üèÜ Performance: F1=49.86% | Pr√©cision=60.73%")
    print("üéØ Seuil optimal: 0.5")
    
    # Charger le mod√®le
    model, device = load_epoch30_model()
    if model is None:
        return
    
    # Trouver les vid√©os
    videos = find_videos()
    if not videos:
        return
    
    # S√©lectionner une vid√©o
    selected_video = select_video(videos)
    if not selected_video:
        print("‚ùå Aucune vid√©o s√©lectionn√©e")
        return
    
    # Traiter la vid√©o
    success = process_video(model, device, selected_video)
    
    if success:
        print(f"\n‚úÖ TRAITEMENT TERMIN√â AVEC SUCC√àS!")
        print(f"üìÅ R√©sultat dans: {OUTPUT_DIR}/")
    else:
        print(f"\n‚ùå Erreur lors du traitement")

if __name__ == "__main__":
    main()
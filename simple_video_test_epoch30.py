#!/usr/bin/env python3
"""
Script SIMPLE pour tester l'√âpoque 30 sur vid√©os
Support: MP4, AVI, MOV, MKV, WMV, MPG, MPEG
Usage: python simple_video_test_epoch30.py
"""

import os
import cv2
import torch
import numpy as np
import torchvision.transforms as transforms
import torchvision.models.detection as detection_models
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
import glob

# Configuration simple
EPOCH_30_MODEL = "output_stable_training/stable_model_epoch_30.pth"
VIDEOS_DIR = "videos"
OUTPUT_DIR = "videos_output"
CONFIDENCE = 0.5  # Seuil optimal d√©montr√©

# Classes du mod√®le (28 classes)
CLASSES_FR = [
    'Personne', 'Sac √† dos', 'Valise', 'Sac √† main', 'Cravate',
    'Parapluie', 'S√®che-cheveux', 'Brosse √† dents', 'T√©l√©phone',
    'Ordinateur portable', 'Clavier', 'Souris', 'T√©l√©commande', 'T√©l√©vision',
    'Horloge', 'Micro-ondes', 'Bouteille', 'Tasse', 'Bol',
    'Couteau', 'Cuill√®re', 'Fourchette', 'Verre', 'R√©frig√©rateur',
    'Ciseaux', 'Livre', 'Vase', 'Chaise'
]

def load_epoch30_model():
    """Charge le mod√®le epoch 30"""
    print("ü§ñ Chargement du mod√®le √âpoque 30...")
    
    if not os.path.exists(EPOCH_30_MODEL):
        print(f"‚ùå Mod√®le non trouv√©: {EPOCH_30_MODEL}")
        return None, None
    
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        model = detection_models.fasterrcnn_resnet50_fpn(weights=None)
        in_features = model.roi_heads.box_predictor.cls_score.in_features
        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 29)  # 28 + fond
        
        model.load_state_dict(torch.load(EPOCH_30_MODEL, map_location=device))
        model.to(device)
        model.eval()
        
        print(f"‚úÖ Mod√®le epoch 30 charg√© sur {device}")
        return model, device
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return None, None

def find_videos():
    """Trouve toutes les vid√©os dans le dossier videos"""
    if not os.path.exists(VIDEOS_DIR):
        print(f"‚ùå Cr√©ez le dossier '{VIDEOS_DIR}' et placez-y vos vid√©os")
        return []
    
    # Extensions vid√©o support√©es (AVEC MPG/MPEG AJOUT√âS)
    extensions = ['*.mp4', '*.avi', '*.mov', '*.mkv', '*.wmv', '*.mpg', '*.mpeg', '*.m4v']
    videos = []
    
    for ext in extensions:
        videos.extend(glob.glob(os.path.join(VIDEOS_DIR, ext)))
        videos.extend(glob.glob(os.path.join(VIDEOS_DIR, ext.upper())))
    
    if not videos:
        print(f"‚ùå Aucune vid√©o trouv√©e dans '{VIDEOS_DIR}'")
        print("üé¨ Formats support√©s: .mp4, .avi, .mov, .mkv, .wmv, .mpg, .mpeg, .m4v")
        print("üí° Placez vos vid√©os dans le dossier 'videos/'")
        return []
    
    print(f"üìπ {len(videos)} vid√©o(s) trouv√©e(s):")
    for i, video in enumerate(videos, 1):
        # Obtenir info sur la vid√©o
        try:
            cap = cv2.VideoCapture(video)
            if cap.isOpened():
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                fps = int(cap.get(cv2.CAP_PROP_FPS))
                frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                duration = frame_count / fps if fps > 0 else 0
                
                # Taille du fichier
                size_mb = os.path.getsize(video) / (1024 * 1024)
                
                print(f"  {i:2d}. {os.path.basename(video):<30} "
                      f"({width}x{height}, {fps}fps, {duration:.1f}s, {size_mb:.1f}MB)")
                cap.release()
            else:
                print(f"  {i:2d}. {os.path.basename(video):<30} (‚ùå Erreur lecture)")
        except:
            print(f"  {i:2d}. {os.path.basename(video):<30} (‚ùì Info indisponible)")
    
    return videos

def select_video(videos):
    """S√©lectionne une vid√©o √† traiter"""
    if len(videos) == 1:
        print(f"üìπ Vid√©o s√©lectionn√©e automatiquement: {os.path.basename(videos[0])}")
        return videos[0]
    
    print(f"\nüéØ S√âLECTION DE LA VID√âO:")
    while True:
        try:
            choice = input(f"\nChoisissez une vid√©o (1-{len(videos)}) ou 'q' pour quitter: ").strip()
            if choice.lower() == 'q':
                return None
            
            idx = int(choice) - 1
            if 0 <= idx < len(videos):
                selected = videos[idx]
                print(f"‚úÖ S√©lectionn√©: {os.path.basename(selected)}")
                return selected
            else:
                print(f"‚ùå Choisissez un nombre entre 1 et {len(videos)}")
        except ValueError:
            print("‚ùå Entrez un nombre valide ou 'q' pour quitter")

def test_video_compatibility(video_path):
    """Test la compatibilit√© de la vid√©o"""
    print(f"\nüîç Test de compatibilit√©: {os.path.basename(video_path)}")
    
    try:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print("‚ùå Impossible d'ouvrir la vid√©o")
            print("üí° Essayez de convertir avec: ffmpeg -i input.mpg output.mp4")
            return False
        
        # Lire quelques frames de test
        ret, frame = cap.read()
        if not ret:
            print("‚ùå Impossible de lire les frames")
            cap.release()
            return False
        
        # V√©rifier les propri√©t√©s
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        
        print(f"‚úÖ Vid√©o compatible:")
        print(f"   üìè R√©solution: {width}x{height}")
        print(f"   üé¨ FPS: {fps}")
        print(f"   üñºÔ∏è Frame test: OK")
        
        cap.release()
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur test: {e}")
        return False

def process_video(model, device, video_path):
    """Traite une vid√©o avec d√©tection"""
    print(f"\nüé¨ TRAITEMENT DE: {os.path.basename(video_path)}")
    print("="*60)
    
    # Test de compatibilit√© d'abord
    if not test_video_compatibility(video_path):
        return False
    
    # Ouvrir la vid√©o
    cap = cv2.VideoCapture(video_path)
    
    # Propri√©t√©s vid√©o
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"üìä Propri√©t√©s: {width}x{height} √† {fps} FPS")
    print(f"‚è±Ô∏è Dur√©e: {total_frames/fps:.1f} secondes ({total_frames} frames)")
    
    # Fichier de sortie
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # Garder l'extension originale dans le nom
    base_name = os.path.splitext(os.path.basename(video_path))[0]
    original_ext = os.path.splitext(video_path)[1]
    output_path = os.path.join(OUTPUT_DIR, f"detected_{base_name}{original_ext}")
    
    # Si c'est un MPG, convertir en MP4 pour la sortie
    if original_ext.lower() in ['.mpg', '.mpeg']:
        output_path = os.path.join(OUTPUT_DIR, f"detected_{base_name}.mp4")
        print(f"üí° Conversion {original_ext} ‚Üí .mp4 pour la sortie")
    
    # Writer pour sauvegarder
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    # Transformation pour le mod√®le
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    # Couleurs al√©atoires pour les classes
    np.random.seed(42)
    colors = [(np.random.randint(50, 255), np.random.randint(50, 255), np.random.randint(50, 255)) 
              for _ in range(28)]
    
    frame_count = 0
    total_detections = 0
    processing_times = []
    
    print("üöÄ Traitement en cours...")
    print("üí° Traitement optimis√© pour performance maximale")
    
    try:
        import time
        start_time = time.time()
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            frame_start_time = time.time()
            
            # Pr√©traitement pour le mod√®le
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frame_tensor = transform(frame_rgb).unsqueeze(0).to(device)
            
            # D√©tection
            with torch.no_grad():
                predictions = model(frame_tensor)
            
            # Extraire r√©sultats
            boxes = predictions[0]['boxes'].cpu().numpy()
            labels = predictions[0]['labels'].cpu().numpy()
            scores = predictions[0]['scores'].cpu().numpy()
            
            # Filtrer par confiance
            mask = scores > CONFIDENCE
            boxes = boxes[mask]
            labels = labels[mask]
            scores = scores[mask]
            
            frame_detections = len(boxes)
            total_detections += frame_detections
            
            # Dessiner les d√©tections
            for box, label, score in zip(boxes, labels, scores):
                x1, y1, x2, y2 = box.astype(int)
                class_idx = label - 1  # -1 car 0 est le fond
                
                if 0 <= class_idx < 28:
                    class_name = CLASSES_FR[class_idx]
                    color = colors[class_idx]
                    
                    # Rectangle de d√©tection
                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                    
                    # Texte avec nom et confiance
                    text = f"{class_name}: {score:.2f}"
                    (text_width, text_height), _ = cv2.getTextSize(
                        text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
                    )
                    
                    # Fond du texte
                    cv2.rectangle(frame, (x1, y1-text_height-10), 
                                (x1+text_width, y1), color, -1)
                    
                    # Texte
                    cv2.putText(frame, text, (x1, y1-5), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)
            
            # Informations sur la frame
            info_text = f"Frame: {frame_count}/{total_frames} | Objets: {frame_detections} | Total: {total_detections}"
            cv2.putText(frame, info_text, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # Informations du mod√®le
            model_info = f"Modele: Epoque 30 | Format: {original_ext.upper()} | Confiance: {CONFIDENCE}"
            cv2.putText(frame, model_info, (10, height-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            # Sauvegarder la frame
            writer.write(frame)
            
            # Mesurer performance
            frame_time = time.time() - frame_start_time
            processing_times.append(frame_time)
            
            # Affichage progression
            if frame_count % 50 == 0:
                progress = (frame_count / total_frames) * 100
                avg_time = np.mean(processing_times[-50:]) if processing_times else 0
                fps_actual = 1.0 / avg_time if avg_time > 0 else 0
                
                print(f"üìà {progress:5.1f}% | {frame_count:4d}/{total_frames} frames | "
                      f"{total_detections:3d} d√©tections | {fps_actual:.1f} fps")
    
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Arr√™t par Ctrl+C")
    
    finally:
        # Nettoyage
        cap.release()
        writer.release()
        
        # Statistiques finales
        end_time = time.time()
        total_time = end_time - start_time
        
        print(f"\nüìä R√âSULTATS FINAUX:")
        print("="*50)
        print(f"   üé¨ Frames trait√©es: {frame_count}/{total_frames}")
        print(f"   üîç Total d√©tections: {total_detections}")
        print(f"   üìà Moyenne par frame: {total_detections/frame_count:.1f}")
        print(f"   ‚è±Ô∏è Temps total: {total_time:.1f}s")
        print(f"   üöÄ Vitesse moyenne: {frame_count/total_time:.1f} fps")
        print(f"   üíæ Vid√©o sauvegard√©e: {output_path}")
        
        # V√©rifier si le fichier de sortie existe
        if os.path.exists(output_path):
            size_mb = os.path.getsize(output_path) / (1024 * 1024)
            print(f"   üìÅ Taille fichier: {size_mb:.1f} MB")
            print(f"   ‚úÖ Format converti: {original_ext} ‚Üí {os.path.splitext(output_path)[1]}")
        
        return True

def main():
    """Fonction principale"""
    print("="*70)
    print("üé¨ TEST VID√âO SIMPLE - MOD√àLE √âPOQUE 30 (AVEC SUPPORT MPG)")
    print("="*70)
    print("üèÜ Performance: F1=49.86% | Pr√©cision=60.73%")
    print("üéØ Seuil optimal: 0.5")
    print("üìπ Formats support√©s: MP4, AVI, MOV, MKV, WMV, MPG, MPEG, M4V")
    
    # Charger le mod√®le
    model, device = load_epoch30_model()
    if model is None:
        return
    
    # Trouver les vid√©os
    videos = find_videos()
    if not videos:
        return
    
    # S√©lectionner une vid√©o
    selected_video = select_video(videos)
    if not selected_video:
        print("‚ùå Aucune vid√©o s√©lectionn√©e")
        return
    
    # Traiter la vid√©o
    success = process_video(model, device, selected_video)
    
    if success:
        print(f"\n‚úÖ TRAITEMENT TERMIN√â AVEC SUCC√àS!")
        print(f"üìÅ R√©sultat dans: {OUTPUT_DIR}/")
        print(f"üí° Conseil: Les fichiers MPG sont convertis en MP4 pour compatibilit√©")
    else:
        print(f"\n‚ùå Erreur lors du traitement")
        print(f"üí° Si probl√®me avec MPG, essayez: ffmpeg -i video.mpg video.mp4")

if __name__ == "__main__":
    main()